import torch  # Th∆∞ vi·ªán deep learning ch√≠nh
import torch.nn as nn  # Module loss, layers
from transformers import BertTokenizer, AdamW  # BERT tokenizer v√† optimizer AdamW
from models.hanet_model import HANetTriggerEncoder  # Import m√¥ h√¨nh HANet ƒë√£ ƒë·ªãnh nghƒ©a
from utils.data_loader import MAVENDataset  # Dataset reader cho file jsonl
from torch.utils.data import DataLoader  # Dataloader ƒë·ªÉ t·∫°o batch
import config  # C·∫•u h√¨nh: model, batch size, learning rate, device
import psutil, os  # ƒê·ªÉ ƒëo l∆∞·ª£ng RAM s·ª≠ d·ª•ng
import warnings
warnings.filterwarnings('ignore')

# √âp s·ª≠ d·ª•ng GPU c·ª• th·ªÉ (A100 g√°n v√†o cuda:0)
config.DEVICE = "cuda:0" if torch.cuda.is_available() else "cpu"

# Kh·ªüi t·∫°o tokenizer BERT
tokenizer = BertTokenizer.from_pretrained(config.BASE_MODEL)

# Kh·ªüi t·∫°o m√¥ h√¨nh v√† chuy·ªÉn sang GPU n·∫øu c√≥
model = HANetTriggerEncoder(config.BASE_MODEL, config.NUM_LABELS).to(config.DEVICE)

# Kh·ªüi t·∫°o optimizer AdamW
optimizer = AdamW(model.parameters(), lr=config.LR)

# T·∫£i d·ªØ li·ªáu t·ª´ base task
data = MAVENDataset("/data/AITeam/nguyetnvm/Hanet/data/small_split/base_task.jsonl", tokenizer)

# T·∫°o th∆∞ m·ª•c l∆∞u checkpoint n·∫øu ch∆∞a c√≥
os.makedirs("/data/AITeam/nguyetnvm/Hanet/checkpoints", exist_ok=True)

# T·∫°o DataLoader ƒë·ªÉ chia batch
dataloader = DataLoader(data, batch_size=config.BATCH_SIZE, shuffle=True)

# B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán
model.train()
best_loss = float("inf")  # Theo d√µi loss t·ªët nh·∫•t ƒë·ªÉ l∆∞u m√¥ h√¨nh

for epoch in range(config.MAX_EPOCHS):  # L·∫∑p qua c√°c epoch
    for batch in dataloader:  # L·∫∑p qua t·ª´ng batch
        input_ids = batch['input_ids'].to(config.DEVICE)  # Tensor input ids
        attention_mask = batch['attention_mask'].to(config.DEVICE)  # Attention mask
        labels = batch['label'].to(config.DEVICE)  # Nh√£n event type
        trigger_pos = batch['trigger_pos'].to(config.DEVICE)  # V·ªã tr√≠ trigger [start, end]

        logits = model(input_ids, attention_mask, trigger_pos)  # Forward pass
        loss = nn.CrossEntropyLoss()(logits, labels)  # T√≠nh loss ph√¢n lo·∫°i

        optimizer.zero_grad()  # Reset gradient
        loss.backward()  # Lan truy·ªÅn gradient
        optimizer.step()  # C·∫≠p nh·∫≠t tr·ªçng s·ªë

    # L∆∞u m√¥ h√¨nh n·∫øu loss t·ªët h∆°n
    if loss.item() < best_loss:
        best_loss = loss.item()
        torch.save(model.state_dict(), "/data/AITeam/nguyetnvm/Hanet/checkpoints/hanet_best_base.pt")
        print(f"üíæ Saved best model at epoch {epoch+1} with loss {best_loss:.4f}")

    # In th√¥ng tin RAM s·ª≠ d·ª•ng sau m·ªói epoch
    process = psutil.Process(os.getpid())
    ram_usage = process.memory_info().rss / 1024 ** 2  # RAM t√≠nh b·∫±ng MB
    print(f"Epoch {epoch+1} | Loss: {loss.item():.4f} | üß† RAM: {ram_usage:.2f} MB")

    # N·∫øu d√πng GPU th√¨ in l∆∞·ª£ng VRAM v√† t√™n thi·∫øt b·ªã
    if torch.cuda.is_available():
        gpu_mem = torch.cuda.memory_allocated() / 1024 ** 2  # VRAM t√≠nh b·∫±ng MB
        device_name = torch.cuda.get_device_name(torch.cuda.current_device())
        print(f"üî• GPU memory: {gpu_mem:.2f} MB | üìü GPU: {device_name}")

